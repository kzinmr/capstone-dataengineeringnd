{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Immigration datawarehousing project\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In this project, we will demonstrate how to build a data warehouse that enriches the analysis of frequently occurring events by augmenting the event data with ancillary information. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import psycopg2\n",
    "from sql_queries import airport_insert, demographic_insert, immigration_insert, temperature_insert"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "We explain the scope of this project in detail:\n",
    "\n",
    "- To aid in the analysis of U.S. immigration data, we expand the dataset with information on the ports through which immigration occurs.\n",
    "  - This information includes data on airports, demographics, and temperatures.\n",
    "- We will finally construct the data warehouse in snowflake schema by building ETL processes which convert original data into these tables.\n",
    "- We use pandas and PostgresSQL in local development.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "We use the following datasets:\n",
    "- **I94 Immigration Data**: This data comes from [the US National Tourism and Trade Office](https://www.trade.gov/national-travel-and-tourism-office).\n",
    "  - A data dictionary exported from SAS is included in the repository: I94_SAS_Labels_Descriptions.SAS.\n",
    "- **Airport Code Table**: This is a simple table of airport codes and corresponding cities published [here](https://datahub.io/core/airport-codes#data).\n",
    "- **U.S. City Demographic Data**: This data comes from [OpenSoft](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/).\n",
    "- **World Temperature Data**: This dataset came from Kaggle kernel: [Climate Change: Earth Surface Temperature Data](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).\n"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df_immigration = pd.read_csv('immigration_data_sample.csv')\n",
    "print(df_immigration.shape)\n",
    "df_immigration = df_immigration.set_index('Unnamed: 0').sort_index()\n",
    "df_immigration.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1000, 29)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "Unnamed: 0                                                                      \n",
       "10925       13208.0  2016.0     4.0   116.0   116.0     LOS  20545.0      1.0   \n",
       "10930       13213.0  2016.0     4.0   116.0   116.0     LOS  20545.0      1.0   \n",
       "11328       13826.0  2016.0     4.0   117.0   117.0     ATL  20545.0      1.0   \n",
       "14575       17786.0  2016.0     4.0   123.0   123.0     NYC  20545.0      1.0   \n",
       "15053       18310.0  2016.0     4.0   123.0   123.0     SEA  20545.0      1.0   \n",
       "\n",
       "           i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto  \\\n",
       "Unnamed: 0                    ...                                           \n",
       "10925           CA  20574.0   ...         NaN        M   1987.0  06292016   \n",
       "10930           CA  20553.0   ...         NaN        M   1981.0  06292016   \n",
       "11328           SC  20553.0   ...         NaN        M   1972.0  06292016   \n",
       "14575           NE  20556.0   ...         NaN        M   1985.0  06292016   \n",
       "15053           CA  20548.0   ...         NaN        M   1971.0  06292016   \n",
       "\n",
       "           gender insnum airline        admnum  fltno visatype  \n",
       "Unnamed: 0                                                      \n",
       "10925           M    NaN      VS  5.544224e+10  00007       WT  \n",
       "10930         NaN    NaN      AA  5.544979e+10  00109       WT  \n",
       "11328           M    NaN      AF  5.545908e+10  00688       WB  \n",
       "14575         NaN    NaN      VS  5.545518e+10  00009       WB  \n",
       "15053           M    NaN      DL  5.542154e+10  00143       WT  \n",
       "\n",
       "[5 rows x 28 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10925</th>\n",
       "      <td>13208.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VS</td>\n",
       "      <td>5.544224e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10930</th>\n",
       "      <td>13213.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>5.544979e+10</td>\n",
       "      <td>00109</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11328</th>\n",
       "      <td>13826.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SC</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>5.545908e+10</td>\n",
       "      <td>00688</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14575</th>\n",
       "      <td>17786.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>20556.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VS</td>\n",
       "      <td>5.545518e+10</td>\n",
       "      <td>00009</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15053</th>\n",
       "      <td>18310.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DL</td>\n",
       "      <td>5.542154e+10</td>\n",
       "      <td>00143</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_airport = pd.read_csv('airport-codes_csv.csv')\n",
    "print(df_airport.shape)\n",
    "df_airport.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(55075, 12)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_demographics = pd.read_csv('us-cities-demographics.csv', delimiter=';')\n",
    "print(df_demographics.shape)\n",
    "df_demographics.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2891, 12)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_temperature = pd.read_csv('GlobalLandTemperaturesByCity.csv')\n",
    "print(df_temperature.shape)\n",
    "df_temperature_us = df_temperature[df_temperature[\"Country\"] == \"United States\"]\n",
    "print(df_temperature_us.shape)\n",
    "df_temperature_us.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8599212, 7)\n",
      "(687289, 7)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "47555  1820-01-01               2.101                          3.217  Abilene   \n",
       "47556  1820-02-01               6.926                          2.853  Abilene   \n",
       "47557  1820-03-01              10.767                          2.395  Abilene   \n",
       "47558  1820-04-01              17.989                          2.202  Abilene   \n",
       "47559  1820-05-01              21.809                          2.036  Abilene   \n",
       "\n",
       "             Country Latitude Longitude  \n",
       "47555  United States   32.95N   100.53W  \n",
       "47556  United States   32.95N   100.53W  \n",
       "47557  United States   32.95N   100.53W  \n",
       "47558  United States   32.95N   100.53W  \n",
       "47559  United States   32.95N   100.53W  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47557</th>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47558</th>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.989</td>\n",
       "      <td>2.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47559</th>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.\\\n",
    "# config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "# config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "# enableHiveSupport().getOrCreate()\n",
    "\n",
    "# df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "# #write to parquet\n",
    "# df_spark.write.parquet(\"sas_data\")\n",
    "# df_spark=spark.read.parquet(\"sas_data\")"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(\"Define valid iata codes, cities and state codes from the SAS description file.\")\n",
    "iata_codes, cities, state_codes = [], [], []\n",
    "\n",
    "with open(\"./I94_SAS_Labels_Descriptions.SAS\") as f:\n",
    "    lines = [l.strip() for l in f]\n",
    "    print(lines[300:302], lines[962:963])\n",
    "    for port in lines[302:962]:\n",
    "        iata_code, city_state = tuple(map(lambda x:x.replace(\"'\",\"\").strip(), port.split(\"=\")))\n",
    "        if len(city_state.rsplit(',', 1)) == 2:\n",
    "            city, state_code = tuple(map(lambda x: x.strip(), city_state.rsplit(',', 1)))\n",
    "            iata_codes.append(iata_code)\n",
    "            cities.append(city)\n",
    "            state_codes.append(state_code)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Define valid iata codes, cities and state codes from the SAS description file.\n",
      "['/* I94PORT - This format shows all the valid and invalid codes for processing */', 'value $i94prtl'] [';']\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(\"Identify columns which have too many NaNs.\")\n",
    "# key: i94port, i94addr\n",
    "[\"visapost\", \"occup\", \"entdepu\", \"insnum\", ]\n",
    "for k in [k for k,v in df_immigration.isnull().any().items() if v]:\n",
    "    print(df_immigration[k].isna().value_counts().sort_index())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Identify columns which have too many NaNs.\n",
      "False    941\n",
      "True      59\n",
      "Name: i94addr, dtype: int64\n",
      "False    951\n",
      "True      49\n",
      "Name: depdate, dtype: int64\n",
      "False    382\n",
      "True     618\n",
      "Name: visapost, dtype: int64\n",
      "False      4\n",
      "True     996\n",
      "Name: occup, dtype: int64\n",
      "False    954\n",
      "True      46\n",
      "Name: entdepd, dtype: int64\n",
      "True    1000\n",
      "Name: entdepu, dtype: int64\n",
      "False    954\n",
      "True      46\n",
      "Name: matflag, dtype: int64\n",
      "False    859\n",
      "True     141\n",
      "Name: gender, dtype: int64\n",
      "False     35\n",
      "True     965\n",
      "Name: insnum, dtype: int64\n",
      "False    967\n",
      "True      33\n",
      "Name: airline, dtype: int64\n",
      "False    992\n",
      "True       8\n",
      "Name: fltno, dtype: int64\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(\"Identify columns which have too many NaNs.\")\n",
    "# key: iata_code\n",
    "[\"continent\", \"local_code\",]\n",
    "for k in [k for k,v in df_airport.isnull().any().items() if v]:\n",
    "    print(df_airport[k].isna().value_counts().sort_index())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Identify columns which have too many NaNs.\n",
      "False    48069\n",
      "True      7006\n",
      "Name: elevation_ft, dtype: int64\n",
      "False    27356\n",
      "True     27719\n",
      "Name: continent, dtype: int64\n",
      "False    54828\n",
      "True       247\n",
      "Name: iso_country, dtype: int64\n",
      "False    49399\n",
      "True      5676\n",
      "Name: municipality, dtype: int64\n",
      "False    41030\n",
      "True     14045\n",
      "Name: gps_code, dtype: int64\n",
      "False     9189\n",
      "True     45886\n",
      "Name: iata_code, dtype: int64\n",
      "False    28686\n",
      "True     26389\n",
      "Name: local_code, dtype: int64\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(\"Identify duplicated key columns.\")\n",
    "_df_airport = df_airport.dropna(subset=['iata_code'])\n",
    "_df_airport = _df_airport[_df_airport[\"iata_code\"].isin(iata_codes)]\n",
    "# _df_airport[]\n",
    "_df_airport = _df_airport[_df_airport['type']!='closed']\n",
    "# _df_airport.drop_duplicates(subset=['iata_code']).shape\n",
    "_df_airport[_df_airport.duplicated(subset=['iata_code'])]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Identify duplicated key columns.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         ident           type                   name  elevation_ft continent  \\\n",
       "40590  RU-0493  small_airport  Dalnerechensk Airport         272.0        EU   \n",
       "\n",
       "      iso_country iso_region   municipality gps_code iata_code local_code  \\\n",
       "40590          RU     RU-PRI  Dalnerechensk      NaN       DLR        NaN   \n",
       "\n",
       "             coordinates  \n",
       "40590  133.7363, 45.8783  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40590</th>\n",
       "      <td>RU-0493</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Dalnerechensk Airport</td>\n",
       "      <td>272.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>RU</td>\n",
       "      <td>RU-PRI</td>\n",
       "      <td>Dalnerechensk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DLR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.7363, 45.8783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(\"Identify columns which have too many NaNs.\")\n",
    "# key: City, State Code\n",
    "for k in [k for k,v in df_demographics.isnull().any().items() if v]:\n",
    "    print(df_demographics[k].isna().value_counts().sort_index())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Identify columns which have too many NaNs.\n",
      "False    2888\n",
      "True        3\n",
      "Name: Male Population, dtype: int64\n",
      "False    2888\n",
      "True        3\n",
      "Name: Female Population, dtype: int64\n",
      "False    2878\n",
      "True       13\n",
      "Name: Number of Veterans, dtype: int64\n",
      "False    2878\n",
      "True       13\n",
      "Name: Foreign-born, dtype: int64\n",
      "False    2875\n",
      "True       16\n",
      "Name: Average Household Size, dtype: int64\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(\"Identify duplicated key columns.\")\n",
    "_df_demographics = df_demographics.dropna(subset=['City'])\n",
    "_df_demographics = _df_demographics[_df_demographics[\"State Code\"].isin(state_codes)]\n",
    "print(\"Note that demographic data has duplicate rows on (city, state) with different the race values.\")\n",
    "_df_demographics[_df_demographics.duplicated(subset=['City', 'State', 'Race'])] #.head(20)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Identify duplicated key columns.\n",
      "Note that demographic data has duplicate rows on (city, state) with different the race values.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [City, State, Median Age, Male Population, Female Population, Total Population, Number of Veterans, Foreign-born, Average Household Size, State Code, Race, Count]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# key: City\n",
    "print(\"Note that temperature data has duplicate rows on city with different (latitude, longitude) values.\")\n",
    "df_temperature_us[df_temperature_us.duplicated(subset=['dt', 'City', 'Latitude', 'Longitude'])]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Note that temperature data has duplicate rows on city with different (latitude, longitude) values.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dt, AverageTemperature, AverageTemperatureUncertainty, City, Country, Latitude, Longitude]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(df_immigration.shape)\n",
    "print(\"Filter rows which have valid port and address values.\")\n",
    "df_immigration_filtered = df_immigration[df_immigration[\"i94port\"].isin(iata_codes)]\n",
    "print(df_immigration_filtered.shape)\n",
    "df_immigration_filtered = df_immigration_filtered[df_immigration_filtered[\"i94addr\"].isin(state_codes)]\n",
    "print(df_immigration_filtered.shape)\n",
    "print(\"Drop columns which have too many NaNs, then drop rows with any NaNs.\")\n",
    "df_immigration_dropped = df_immigration_filtered.drop(columns=[\"insnum\", \"entdepu\", \"occup\", \"visapost\"])\n",
    "df_immigration_notnull = df_immigration_dropped.dropna()\n",
    "print(df_immigration_notnull.shape)\n",
    "\n",
    "df_immigration_notnull.isnull().any()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1000, 28)\n",
      "Filter rows which have valid port and address values.\n",
      "(973, 28)\n",
      "(904, 28)\n",
      "Drop columns which have too many NaNs, then drop rows with any NaNs.\n",
      "(726, 24)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "cicid       False\n",
       "i94yr       False\n",
       "i94mon      False\n",
       "i94cit      False\n",
       "i94res      False\n",
       "i94port     False\n",
       "arrdate     False\n",
       "i94mode     False\n",
       "i94addr     False\n",
       "depdate     False\n",
       "i94bir      False\n",
       "i94visa     False\n",
       "count       False\n",
       "dtadfile    False\n",
       "entdepa     False\n",
       "entdepd     False\n",
       "matflag     False\n",
       "biryear     False\n",
       "dtaddto     False\n",
       "gender      False\n",
       "airline     False\n",
       "admnum      False\n",
       "fltno       False\n",
       "visatype    False\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print(\"Filter rows which have valid port and address values.\")\n",
    "df_airport_filtered = df_airport.dropna(subset=['iata_code'])\n",
    "print(df_airport_filtered.shape)\n",
    "df_airport_filtered = df_airport_filtered[df_airport_filtered[\"iata_code\"].isin(iata_codes)]\n",
    "print(df_airport_filtered.shape)\n",
    "df_airport_filtered = df_airport_filtered[df_airport_filtered['type']!='closed']\n",
    "df_airport_filtered = df_airport_filtered.drop_duplicates(subset=['iata_code'])\n",
    "print(df_airport_filtered.shape)\n",
    "\n",
    "print(\"Identify columns which have too many NaNs.\")\n",
    "[\"continent\", \"local_code\", ]\n",
    "for k in [k for k,v in df_airport_filtered.isnull().any().items() if v]:\n",
    "    print(df_airport_filtered[k].isna().value_counts().sort_index())\n",
    "print(\"Drop columns which have too many NaNs, then drop rows with any NaNs.\")\n",
    "df_airport_dropped = df_airport_filtered.drop(columns=[\"continent\", \"local_code\", ])\n",
    "df_airport_notnull = df_airport_dropped.dropna()\n",
    "print(df_airport_notnull.shape)\n",
    "df_airport_notnull.isnull().any()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Filter rows which have valid port and address values.\n",
      "(9189, 12)\n",
      "(510, 12)\n",
      "(495, 12)\n",
      "Identify columns which have too many NaNs.\n",
      "False    479\n",
      "True      16\n",
      "Name: elevation_ft, dtype: int64\n",
      "False    220\n",
      "True     275\n",
      "Name: continent, dtype: int64\n",
      "False    494\n",
      "True       1\n",
      "Name: iso_country, dtype: int64\n",
      "False    468\n",
      "True      27\n",
      "Name: municipality, dtype: int64\n",
      "False    476\n",
      "True      19\n",
      "Name: gps_code, dtype: int64\n",
      "False    283\n",
      "True     212\n",
      "Name: local_code, dtype: int64\n",
      "Drop columns which have too many NaNs, then drop rows with any NaNs.\n",
      "(440, 10)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ident           False\n",
       "type            False\n",
       "name            False\n",
       "elevation_ft    False\n",
       "iso_country     False\n",
       "iso_region      False\n",
       "municipality    False\n",
       "gps_code        False\n",
       "iata_code       False\n",
       "coordinates     False\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(df_demographics.shape)\n",
    "print(\"Filter rows which have valid state code values.\")\n",
    "df_demographics_filtered = df_demographics[df_demographics[\"State Code\"].isin(state_codes)]\n",
    "print(df_demographics_filtered.shape)\n",
    "print(\"Drop columns which have any NaNs.\")\n",
    "df_demographics_notnull = df_demographics_filtered.dropna()\n",
    "print(df_demographics_notnull.shape)\n",
    "df_demographics_notnull.isnull().any()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2891, 12)\n",
      "Filter rows which have valid state code values.\n",
      "(2886, 12)\n",
      "Drop columns which have any NaNs.\n",
      "(2870, 12)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "City                      False\n",
       "State                     False\n",
       "Median Age                False\n",
       "Male Population           False\n",
       "Female Population         False\n",
       "Total Population          False\n",
       "Number of Veterans        False\n",
       "Foreign-born              False\n",
       "Average Household Size    False\n",
       "State Code                False\n",
       "Race                      False\n",
       "Count                     False\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "print(df_temperature_us.shape)\n",
    "print(\"Filter rows to the last five years.\")\n",
    "df_temperature_us_copied = df_temperature_us.copy()\n",
    "df_temperature_us_copied.dt = pd.to_datetime(df_temperature_us_copied.dt)\n",
    "df_temperature_us_last = df_temperature_us_copied.set_index('dt').sort_index().last('5Y')\n",
    "df_temperature_us_last = df_temperature_us_last.reset_index()\n",
    "print(df_temperature_us_last.shape)\n",
    "print(\"Filter rows which have valid city values.\")\n",
    "cities_l = [city.lower() for city in cities]\n",
    "df_temperature_us_filtered = df_temperature_us_last[df_temperature_us_last[\"City\"].str.lower().isin(cities_l)]\n",
    "print(df_temperature_us_filtered.shape)\n",
    "print(\"Drop columns which have any NaNs.\")\n",
    "df_temperature_us_notnull = df_temperature_us_filtered.dropna()\n",
    "print(df_temperature_us_notnull.shape)\n",
    "df_temperature_us_notnull.isnull().any()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(687289, 7)\n",
      "Filter rows to the last five years.\n",
      "(14649, 7)\n",
      "Filter rows which have valid city values.\n",
      "(5244, 7)\n",
      "Drop columns which have any NaNs.\n",
      "(5243, 7)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dt                               False\n",
       "AverageTemperature               False\n",
       "AverageTemperatureUncertainty    False\n",
       "City                             False\n",
       "Country                          False\n",
       "Latitude                         False\n",
       "Longitude                        False\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "We chose the data model in the following table and the reasons are following:\n",
    "- We take immigration data as the fact table because this is frequently generated event data.\n",
    "- We take airports, demographics and temperature data as the dimension tables because they can be joined via airport location keys, including iata code, city name and state code.\n",
    "\n",
    "\n",
    "| table name | description | columns |\n",
    "| ------- | ---------- | ----------- |\n",
    "| immigrations | A fact table which stores all immigrations data. | \\|cicid\\|year\\|month\\|cit\\|res\\|iata\\|arrdate\\|mode\\|addr\\|depdate\\|bir\\|visa\\|coun\\|dtadfil\\|visapost\\|occup\\|entdepa\\|entdepd\\|entdepu\\|matflag\\|biryear\\|dtaddto\\|gender\\|insnum\\|airline\\|admnum\\|fltno\\|visatype\\| |\n",
    "| airports | A dimension table which stores airport information. | \\|iata_code\\|name\\|type\\|coordinates\\|city\\|state_code\\|iso_country\\|iso_region\\|gps_code\\| |\n",
    "| demographics | A dimension table which stores demographics of cities in the U.S. | \\|city\\|state_code\\|state\\|race\\|count\\|male_population\\|female_population\\|total_population\\|media_age\\|num_veterans\\|foreign_born\\|average_household_size\\| |\n",
    "| temperatures | A dimension table which stores temperature in the U.S. | \\|timestamp\\|average_temperature\\|average_temperatur_uncertainty\\|city\\|country\\|latitude\\|longitude\\| |"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Join port locations in immigration data to airports data.\n",
    "2. Rename and sort columns of each table data to match the schema.\n",
    "3. Create database and each tables by executing create_tables.py.\n",
    "4. Insert data into created tables."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "df_immigration_port = pd.DataFrame({\"iata_code\" : iata_codes, \"city\": cities, \"state_code\": state_codes})\n",
    "df_airport_joined = df_airport_notnull.merge(df_immigration_port, left_on=\"iata_code\", right_on=\"iata_code\")\n",
    "df_airport_model = df_airport_joined[\n",
    "    [\n",
    "        \"iata_code\",\n",
    "        \"name\",\n",
    "        \"type\",\n",
    "        \"coordinates\",\n",
    "        \"city\",\n",
    "        \"state_code\",\n",
    "        \"iso_country\",\n",
    "        \"iso_region\",\n",
    "        \"gps_code\",\n",
    "    ]\n",
    "]"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "df_demographics_rn = df_demographics_notnull.rename(columns={\n",
    "    \"City\": \"city\",\n",
    "    \"State\": \"state\",\n",
    "    \"Median Age\": \"median_age\",\n",
    "    \"Male Population\": \"male_population\",\n",
    "    \"Female Population\": \"female_population\",\n",
    "    \"Total Population\": \"total_population\",\n",
    "    \"Number of Veterans\": \"num_veterans\",\n",
    "    \"Foreign-born\": \"foreign_born\",\n",
    "    \"Average Household Size\": \"average_household_size\",\n",
    "    \"State Code\": \"state_code\",\n",
    "    \"Race\": \"race\",\n",
    "    \"Count\": \"count\",\n",
    "})\n",
    "df_demographics_model = df_demographics_rn[\n",
    "    [\n",
    "        \"city\",\n",
    "        \"state_code\",\n",
    "        \"state\",\n",
    "        \"race\",\n",
    "        \"count\",\n",
    "        \"male_population\",\n",
    "        \"female_population\",\n",
    "        \"total_population\",\n",
    "        \"median_age\",\n",
    "        \"num_veterans\",\n",
    "        \"foreign_born\",\n",
    "        \"average_household_size\",\n",
    "    ]\n",
    "]"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# [\"insnum\", \"entdepu\", \"occup\", \"visapost\"]\n",
    "df_immigration_notnull_rn = df_immigration_notnull.rename(columns={\n",
    "    \"cicid\": \"cicid\",\n",
    "    \"i94yr\": \"year\",\n",
    "    \"i94mon\": \"month\",\n",
    "    \"i94cit\": \"cit\",\n",
    "    \"i94res\": \"res\",\n",
    "    \"i94port\": \"iata\",\n",
    "    \"arrdate\": \"arrdate\",\n",
    "    \"i94mode\": \"mode\",\n",
    "    \"i94addr\": \"addr\",\n",
    "    \"depdate\": \"depdate\",\n",
    "    \"i94bir\": \"bir\",\n",
    "    \"i94visa\": \"visa\",\n",
    "    \"count\": \"count\",\n",
    "    \"dtadfile\": \"date_added\",\n",
    "    \"entdepa\": \"entdepa\",\n",
    "    \"entdepd\": \"entdepd\",\n",
    "    \"matflag\": \"matflag\",\n",
    "    \"biryear\": \"biryear\",\n",
    "    \"dtaddto\": \"dtaddto\",\n",
    "    \"gender\": \"gender\",\n",
    "    \"airline\": \"airline\",\n",
    "    \"admnum\": \"admnum\",\n",
    "    \"fltno\": \"fltno\",\n",
    "    \"visatype\": \"visatype\",\n",
    "})\n",
    "\n",
    "df_immigration_model = df_immigration_notnull_rn[\n",
    "    [\n",
    "        \"cicid\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        \"cit\",\n",
    "        \"res\",\n",
    "        \"iata\",\n",
    "        \"arrdate\",\n",
    "        \"mode\",\n",
    "        \"addr\",\n",
    "        \"depdate\",\n",
    "        \"bir\",\n",
    "        \"visa\",\n",
    "        \"count\",\n",
    "        \"date_added\",\n",
    "        \"entdepa\",\n",
    "        \"entdepd\",\n",
    "        \"matflag\",\n",
    "        \"biryear\",\n",
    "        \"dtaddto\",\n",
    "        \"gender\",\n",
    "        \"airline\",\n",
    "        \"admnum\",\n",
    "        \"fltno\",\n",
    "        \"visatype\",\n",
    "    ]\n",
    "]"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "df_temperature_us_notnull_rn = df_temperature_us_notnull.rename(columns={\n",
    "    \"dt\": \"timestamp\",\n",
    "    \"AverageTemperature\": \"average_temperature\",\n",
    "    \"AverageTemperatureUncertainty\": \"average_temperature_uncertainty\",\n",
    "    \"City\": \"city\",\n",
    "    \"Country\": \"country\",\n",
    "    \"Latitude\": \"latitude\",\n",
    "    \"Longitude\": \"longitude\",\n",
    "})\n",
    "df_temperature_us_model = df_temperature_us_notnull_rn[\n",
    "    [\n",
    "        \"timestamp\",\n",
    "        \"average_temperature\",\n",
    "        \"average_temperature_uncertainty\",\n",
    "        \"city\",\n",
    "        \"country\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "    ]\n",
    "]"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "!python create_tables.py"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "connecting to postgres...\n",
      "DROP EXISTING TABLES...\n",
      "CREATE TABLES...\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Insert data\n",
    "import configparser\n",
    "import psycopg2\n",
    "from sql_queries import airport_insert, demographic_insert, immigration_insert, temperature_insert\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"db.cfg\")\n",
    "conn = psycopg2.connect(\n",
    "    \"host={} dbname={} user={} password={} port={}\".format(\n",
    "        *config[\"LOCAL\"].values()\n",
    "    )\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "for index, row in df_airport_model.iterrows():\n",
    "    cur.execute(airport_insert, list(row.values))\n",
    "    conn.commit()\n",
    "\n",
    "for index, row in df_demographics_model.iterrows():\n",
    "    cur.execute(demographic_insert, list(row.values))\n",
    "    conn.commit()\n",
    "\n",
    "for index, row in df_immigration_model.iterrows():\n",
    "    cur.execute(immigration_insert, list(row.values))\n",
    "    conn.commit()\n",
    "\n",
    "for index, row in df_temperature_us_model.iterrows():\n",
    "    cur.execute(temperature_insert, list(row.values))\n",
    "    conn.commit()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# conn.close()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Perform quality checks here\n",
    "def assert_count(cur, conn, table):\n",
    "    \"\"\" Assert that the given has any rows.\n",
    "    Args:\n",
    "        cur: SQL cursor object.\n",
    "        conn: DB connection object.\n",
    "        table: The name of table to check.\n",
    "    Returns:\n",
    "    Raises:\n",
    "        AssertionError\n",
    "    \"\"\"\n",
    "    cur.execute(f\"select count(*) from {table}\")\n",
    "    conn.commit()\n",
    "    assert cur.rowcount >= 1\n",
    "\n",
    "assert_count(cur, conn, \"airports\")\n",
    "assert_count(cur, conn, \"demographics\")\n",
    "assert_count(cur, conn, \"immigrations\")\n",
    "assert_count(cur, conn, \"temperatures\")"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "conn.close()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "  - We use pandas and PostgresSQL in local development. If large scale analysis is needed, these can be naturally extended to Spark and Redshift for scaling.\n",
    "\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "  - We should update the data on a monthly basis since the dataset describes immigration information that is aggregated monthly.\n",
    "\n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    "  * The data was increased by 100x.\n",
    "    - We should use Spark cluster with EMR for example to scale out ETL process. If SQL querying is slow, use columnar database like Redshift.\n",
    "  * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "    - We sholud use data workflow system like Airflow to schedule our ETL pipeline execution.\n",
    "  * The database needed to be accessed by 100+ people.\n",
    "    - We could scale out Redshift cluster to handle a large number of user requests. \n"
   ],
   "metadata": {
    "editable": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}