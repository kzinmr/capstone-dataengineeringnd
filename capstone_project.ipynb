{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Immigration datawarehousing project\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In this project, we will demonstrate how to build a data warehouse that enriches the analysis of frequently occurring events by augmenting the event data with ancillary information. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import psycopg2\n",
    "from sql_queries import airport_insert, demographic_insert, immigration_insert, temperature_insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "We explain the scope of this project in detail:\n",
    "\n",
    "- To aid in the analysis of U.S. immigration data, we expand the dataset with information on the ports through which immigration occurs.\n",
    "  - This information includes data on airports, demographics, and temperatures.\n",
    "- We will finally construct the data warehouse in snowflake schema by building ETL processes which convert original data into these tables.\n",
    "- With this data warehouse, various analyses can be performed,such as getting an insight into immigration patterns to a city based on the overall population of the state.\n",
    "- We use pandas and PostgresSQL in local development.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "We use the following datasets:\n",
    "- **I94 Immigration Data**: This data comes from [the US National Tourism and Trade Office](https://www.trade.gov/national-travel-and-tourism-office).\n",
    "  - A data dictionary exported from SAS is included in the repository: I94_SAS_Labels_Descriptions.SAS.\n",
    "- **Airport Code Table**: This is a simple table of airport codes and corresponding cities published [here](https://datahub.io/core/airport-codes#data).\n",
    "- **U.S. City Demographic Data**: This data comes from [OpenSoft](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/).\n",
    "- **World Temperature Data**: This dataset came from Kaggle kernel: [Climate Change: Earth Surface Temperature Data](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10925</th>\n",
       "      <td>13208.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VS</td>\n",
       "      <td>5.544224e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10930</th>\n",
       "      <td>13213.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>5.544979e+10</td>\n",
       "      <td>00109</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11328</th>\n",
       "      <td>13826.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SC</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>5.545908e+10</td>\n",
       "      <td>00688</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14575</th>\n",
       "      <td>17786.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>20556.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VS</td>\n",
       "      <td>5.545518e+10</td>\n",
       "      <td>00009</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15053</th>\n",
       "      <td>18310.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DL</td>\n",
       "      <td>5.542154e+10</td>\n",
       "      <td>00143</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "Unnamed: 0                                                                      \n",
       "10925       13208.0  2016.0     4.0   116.0   116.0     LOS  20545.0      1.0   \n",
       "10930       13213.0  2016.0     4.0   116.0   116.0     LOS  20545.0      1.0   \n",
       "11328       13826.0  2016.0     4.0   117.0   117.0     ATL  20545.0      1.0   \n",
       "14575       17786.0  2016.0     4.0   123.0   123.0     NYC  20545.0      1.0   \n",
       "15053       18310.0  2016.0     4.0   123.0   123.0     SEA  20545.0      1.0   \n",
       "\n",
       "           i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto  \\\n",
       "Unnamed: 0                    ...                                           \n",
       "10925           CA  20574.0   ...         NaN        M   1987.0  06292016   \n",
       "10930           CA  20553.0   ...         NaN        M   1981.0  06292016   \n",
       "11328           SC  20553.0   ...         NaN        M   1972.0  06292016   \n",
       "14575           NE  20556.0   ...         NaN        M   1985.0  06292016   \n",
       "15053           CA  20548.0   ...         NaN        M   1971.0  06292016   \n",
       "\n",
       "           gender insnum airline        admnum  fltno visatype  \n",
       "Unnamed: 0                                                      \n",
       "10925           M    NaN      VS  5.544224e+10  00007       WT  \n",
       "10930         NaN    NaN      AA  5.544979e+10  00109       WT  \n",
       "11328           M    NaN      AF  5.545908e+10  00688       WB  \n",
       "14575         NaN    NaN      VS  5.545518e+10  00009       WB  \n",
       "15053           M    NaN      DL  5.542154e+10  00143       WT  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration = pd.read_csv('immigration_data_sample.csv')\n",
    "print(df_immigration.shape)\n",
    "df_immigration = df_immigration.set_index('Unnamed: 0').sort_index()\n",
    "df_immigration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55075, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport = pd.read_csv('airport-codes_csv.csv')\n",
    "print(df_airport.shape)\n",
    "df_airport.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics = pd.read_csv('us-cities-demographics.csv', delimiter=';')\n",
    "print(df_demographics.shape)\n",
    "df_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8599212, 7)\n",
      "(687289, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47557</th>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47558</th>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.989</td>\n",
       "      <td>2.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47559</th>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "47555  1820-01-01               2.101                          3.217  Abilene   \n",
       "47556  1820-02-01               6.926                          2.853  Abilene   \n",
       "47557  1820-03-01              10.767                          2.395  Abilene   \n",
       "47558  1820-04-01              17.989                          2.202  Abilene   \n",
       "47559  1820-05-01              21.809                          2.036  Abilene   \n",
       "\n",
       "             Country Latitude Longitude  \n",
       "47555  United States   32.95N   100.53W  \n",
       "47556  United States   32.95N   100.53W  \n",
       "47557  United States   32.95N   100.53W  \n",
       "47558  United States   32.95N   100.53W  \n",
       "47559  United States   32.95N   100.53W  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature = pd.read_csv('GlobalLandTemperaturesByCity.csv')\n",
    "print(df_temperature.shape)\n",
    "df_temperature_us = df_temperature[df_temperature[\"Country\"] == \"United States\"]\n",
    "print(df_temperature_us.shape)\n",
    "df_temperature_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.\\\n",
    "# config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "# config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "# enableHiveSupport().getOrCreate()\n",
    "\n",
    "# df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "# #write to parquet\n",
    "# df_spark.write.parquet(\"sas_data\")\n",
    "# df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read valid iata codes, cities and state codes from the SAS description file.\n",
      "['/* I94PORT - This format shows all the valid and invalid codes for processing */', 'value $i94prtl'] [';']\n"
     ]
    }
   ],
   "source": [
    "def read_sas_dictionary():\n",
    "    \"\"\"Read data dictionary of the immigration dataset in SAS format.\n",
    "    Args:\n",
    "    Returns:\n",
    "        iata_codes: Valid IATA codes specified in the SAS dictionary.\n",
    "        cities: Valid cities specified in the SAS dictionary.\n",
    "        state_codes: Valid state codes specified in the SAS dictionary.\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    print(\"Read valid iata codes, cities and state codes from the SAS description file.\")\n",
    "    iata_codes, cities, state_codes = [], [], []\n",
    "\n",
    "    with open(\"./I94_SAS_Labels_Descriptions.SAS\") as f:\n",
    "        lines = [l.strip() for l in f]\n",
    "        print(lines[300:302], lines[962:963])\n",
    "        for port in lines[302:962]:\n",
    "            iata_code, city_state = tuple(map(lambda x:x.replace(\"'\",\"\").strip(), port.split(\"=\")))\n",
    "            if len(city_state.rsplit(',', 1)) == 2:\n",
    "                city, state_code = tuple(map(lambda x: x.strip(), city_state.rsplit(',', 1)))\n",
    "                iata_codes.append(iata_code)\n",
    "                cities.append(city)\n",
    "                state_codes.append(state_code)\n",
    "    return iata_codes, cities, state_codes\n",
    "\n",
    "\n",
    "iata_codes, cities, state_codes = read_sas_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_na_counts(df):\n",
    "    \"\"\"Show columns of given dataframe which have too many NaNs.\n",
    "    Args:\n",
    "        df: dataframe to be checked.\n",
    "    Returns:\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    print(\"Identify columns which have too many NaNs.\")\n",
    "    for k in [k for k,v in df.isnull().any().items() if v]:\n",
    "        print(df[k].isna().value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identify columns which have too many NaNs.\n",
      "False    941\n",
      "True      59\n",
      "Name: i94addr, dtype: int64\n",
      "False    951\n",
      "True      49\n",
      "Name: depdate, dtype: int64\n",
      "False    382\n",
      "True     618\n",
      "Name: visapost, dtype: int64\n",
      "False      4\n",
      "True     996\n",
      "Name: occup, dtype: int64\n",
      "False    954\n",
      "True      46\n",
      "Name: entdepd, dtype: int64\n",
      "True    1000\n",
      "Name: entdepu, dtype: int64\n",
      "False    954\n",
      "True      46\n",
      "Name: matflag, dtype: int64\n",
      "False    859\n",
      "True     141\n",
      "Name: gender, dtype: int64\n",
      "False     35\n",
      "True     965\n",
      "Name: insnum, dtype: int64\n",
      "False    967\n",
      "True      33\n",
      "Name: airline, dtype: int64\n",
      "False    992\n",
      "True       8\n",
      "Name: fltno, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# key: i94port, i94addr\n",
    "# [\"visapost\", \"occup\", \"entdepu\", \"insnum\", ]\n",
    "print_na_counts(df_immigration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identify columns which have too many NaNs.\n",
      "False    48069\n",
      "True      7006\n",
      "Name: elevation_ft, dtype: int64\n",
      "False    27356\n",
      "True     27719\n",
      "Name: continent, dtype: int64\n",
      "False    54828\n",
      "True       247\n",
      "Name: iso_country, dtype: int64\n",
      "False    49399\n",
      "True      5676\n",
      "Name: municipality, dtype: int64\n",
      "False    41030\n",
      "True     14045\n",
      "Name: gps_code, dtype: int64\n",
      "False     9189\n",
      "True     45886\n",
      "Name: iata_code, dtype: int64\n",
      "False    28686\n",
      "True     26389\n",
      "Name: local_code, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# key: iata_code\n",
    "# [\"continent\", \"local_code\",]\n",
    "print_na_counts(df_airport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identify duplicated key columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40590</th>\n",
       "      <td>RU-0493</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Dalnerechensk Airport</td>\n",
       "      <td>272.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>RU</td>\n",
       "      <td>RU-PRI</td>\n",
       "      <td>Dalnerechensk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DLR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.7363, 45.8783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ident           type                   name  elevation_ft continent  \\\n",
       "40590  RU-0493  small_airport  Dalnerechensk Airport         272.0        EU   \n",
       "\n",
       "      iso_country iso_region   municipality gps_code iata_code local_code  \\\n",
       "40590          RU     RU-PRI  Dalnerechensk      NaN       DLR        NaN   \n",
       "\n",
       "             coordinates  \n",
       "40590  133.7363, 45.8783  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Identify duplicated key columns.\")\n",
    "_df_airport = df_airport.dropna(subset=['iata_code'])\n",
    "_df_airport = _df_airport[_df_airport[\"iata_code\"].isin(iata_codes)]\n",
    "_df_airport = _df_airport[_df_airport['type']!='closed']\n",
    "# _df_airport.drop_duplicates(subset=['iata_code']).shape\n",
    "_df_airport[_df_airport.duplicated(subset=['iata_code'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identify columns which have too many NaNs.\n",
      "False    2888\n",
      "True        3\n",
      "Name: Male Population, dtype: int64\n",
      "False    2888\n",
      "True        3\n",
      "Name: Female Population, dtype: int64\n",
      "False    2878\n",
      "True       13\n",
      "Name: Number of Veterans, dtype: int64\n",
      "False    2878\n",
      "True       13\n",
      "Name: Foreign-born, dtype: int64\n",
      "False    2875\n",
      "True       16\n",
      "Name: Average Household Size, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# key: City, State Code\n",
    "print_na_counts(df_demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identify duplicated key columns.\n",
      "Note that demographic data has duplicate rows on (city, state) with different the race values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [City, State, Median Age, Male Population, Female Population, Total Population, Number of Veterans, Foreign-born, Average Household Size, State Code, Race, Count]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Identify duplicated key columns.\")\n",
    "_df_demographics = df_demographics.dropna(subset=['City'])\n",
    "_df_demographics = _df_demographics[_df_demographics[\"State Code\"].isin(state_codes)]\n",
    "print(\"Note that demographic data has duplicate rows on (city, state) with different the race values.\")\n",
    "_df_demographics[_df_demographics.duplicated(subset=['City', 'State', 'Race'])] #.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that temperature data has duplicate rows on city with different (latitude, longitude) values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dt, AverageTemperature, AverageTemperatureUncertainty, City, Country, Latitude, Longitude]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key: City\n",
    "print(\"Note that temperature data has duplicate rows on city with different (latitude, longitude) values.\")\n",
    "df_temperature_us[df_temperature_us.duplicated(subset=['dt', 'City', 'Latitude', 'Longitude'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Common cleaning steps among tables.\n",
    "\n",
    "def filter_valid_columnvalues(df, colname, valid_values):\n",
    "    \"\"\"Filter rows which have valid values specified in given list.\n",
    "    Args:\n",
    "        df: Dataframe to be cleansed.\n",
    "        colname: The column name to be checked.\n",
    "        valid_values: Valid values in the given column.\n",
    "    Returns:\n",
    "        df_filtered: Filtered dataframe.\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    print(f\"Filter rows which have valid {colname} values.\")\n",
    "    df_filtered = df[df[colname].isin(valid_values)]\n",
    "    return df_filtered\n",
    "\n",
    "def filtercols_then_dropna(df, drop_columns):\n",
    "    \"\"\"Drop specified columns which have too many NaNs,\n",
    "    then drop rows with any NaNs.\n",
    "    Args:\n",
    "        df: Dataframe to be cleansed.\n",
    "        drop_columns: Columns which have too many NaNs.\n",
    "    Returns:\n",
    "        df_notnull: Cleansed dataframe.\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    print(\"Drop columns which have too many NaNs, drop rows with any NaNs.\")\n",
    "    if drop_columns:\n",
    "        df = df.drop(columns=drop_columns)\n",
    "    df_notnull = df.dropna()\n",
    "    return df_notnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28)\n",
      "Filter rows which have valid i94port values.\n",
      "Filter rows which have valid i94addr values.\n",
      "(904, 28)\n",
      "Drop columns which have too many NaNs, drop rows with any NaNs.\n",
      "(726, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cicid       False\n",
       "i94yr       False\n",
       "i94mon      False\n",
       "i94cit      False\n",
       "i94res      False\n",
       "i94port     False\n",
       "arrdate     False\n",
       "i94mode     False\n",
       "i94addr     False\n",
       "depdate     False\n",
       "i94bir      False\n",
       "i94visa     False\n",
       "count       False\n",
       "dtadfile    False\n",
       "entdepa     False\n",
       "entdepd     False\n",
       "matflag     False\n",
       "biryear     False\n",
       "dtaddto     False\n",
       "gender      False\n",
       "airline     False\n",
       "admnum      False\n",
       "fltno       False\n",
       "visatype    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_immigration(df, iata_codes, state_codes):\n",
    "    \"\"\"Cleanse immigration dataframe.\n",
    "    Args:\n",
    "        df: Dataframe to be cleansed.\n",
    "    Returns:\n",
    "        df_notnull: Cleansed dataframe.\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    print(df.shape)\n",
    "    _df = filter_valid_columnvalues(df, \"i94port\", valid_values=iata_codes)\n",
    "    df_filtered = filter_valid_columnvalues(_df, \"i94addr\", valid_values=state_codes)\n",
    "    print(df_filtered.shape)\n",
    "    df_notnull = filtercols_then_dropna(df_filtered, drop_columns=[\"insnum\", \"entdepu\", \"occup\", \"visapost\"])\n",
    "    print(df_notnull.shape)\n",
    "    return df_notnull\n",
    "\n",
    "df_immigration_notnull = clean_immigration(df_immigration, iata_codes, state_codes)\n",
    "df_immigration_notnull.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55075, 12)\n",
      "(8798, 12)\n",
      "Filter rows which have valid iata_code values.\n",
      "(495, 12)\n",
      "Drop columns which have too many NaNs, drop rows with any NaNs.\n",
      "(440, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ident           False\n",
       "type            False\n",
       "name            False\n",
       "elevation_ft    False\n",
       "iso_country     False\n",
       "iso_region      False\n",
       "municipality    False\n",
       "gps_code        False\n",
       "iata_code       False\n",
       "coordinates     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_airport(df, iata_codes):\n",
    "    \"\"\"Cleanse airport dataframe.\n",
    "    Args:\n",
    "        df: Dataframe to be cleansed.\n",
    "    Returns:\n",
    "        df_notnull: Cleansed dataframe.\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    print(df.shape)\n",
    "    _df = df.dropna(subset=['iata_code'])\n",
    "    _df = _df[_df['type']!='closed']\n",
    "    _df = _df.drop_duplicates(subset=['iata_code'])\n",
    "    print(_df.shape)\n",
    "    df_filtered = filter_valid_columnvalues(_df, \"iata_code\", valid_values=iata_codes)\n",
    "    print(df_filtered.shape)\n",
    "    df_notnull = filtercols_then_dropna(df_filtered, drop_columns=[\"continent\", \"local_code\", ])\n",
    "    print(df_notnull.shape)\n",
    "    return df_notnull\n",
    "\n",
    "df_airport_notnull = clean_airport(df_airport, iata_codes)\n",
    "df_airport_notnull.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2891, 12)\n",
      "Filter rows which have valid State Code values.\n",
      "(2886, 12)\n",
      "Drop columns which have too many NaNs, drop rows with any NaNs.\n",
      "(2870, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "City                      False\n",
       "State                     False\n",
       "Median Age                False\n",
       "Male Population           False\n",
       "Female Population         False\n",
       "Total Population          False\n",
       "Number of Veterans        False\n",
       "Foreign-born              False\n",
       "Average Household Size    False\n",
       "State Code                False\n",
       "Race                      False\n",
       "Count                     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_demographics(df, state_codes):\n",
    "    \"\"\"Cleanse demographics dataframe.\n",
    "    Args:\n",
    "        df: Dataframe to be cleansed.\n",
    "    Returns:\n",
    "        df_notnull: Cleansed dataframe.\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    print(df.shape)\n",
    "    df_filtered = filter_valid_columnvalues(df, \"State Code\", valid_values=state_codes)\n",
    "    print(df_filtered.shape)\n",
    "    df_notnull = filtercols_then_dropna(df_filtered, drop_columns=[])\n",
    "    print(df_notnull.shape)\n",
    "    return df_notnull\n",
    "\n",
    "df_demographics_notnull = clean_demographics(df_demographics, state_codes)\n",
    "df_demographics_notnull.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(687289, 7)\n",
      "Filter rows to the last five years.\n",
      "(14649, 7)\n",
      "Filter rows which have valid City_lower values.\n",
      "(5244, 8)\n",
      "Drop columns which have too many NaNs, drop rows with any NaNs.\n",
      "(5243, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dt                               False\n",
       "AverageTemperature               False\n",
       "AverageTemperatureUncertainty    False\n",
       "City                             False\n",
       "Country                          False\n",
       "Latitude                         False\n",
       "Longitude                        False\n",
       "City_lower                       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_temperature(df, cities):\n",
    "    \"\"\"Cleanse temperature dataframe.\n",
    "    Args:\n",
    "        df: Dataframe to be cleansed.\n",
    "    Returns:\n",
    "        df_notnull: Cleansed dataframe.\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    print(df.shape)\n",
    "    print(\"Filter rows to the last five years.\")\n",
    "    df_copied = df.copy()\n",
    "    df_copied.dt = pd.to_datetime(df_copied.dt)\n",
    "    df_last = df_copied.set_index('dt').sort_index().last('5Y')\n",
    "    df_last = df_last.reset_index()\n",
    "    print(df_last.shape)\n",
    "    _df = df_last.copy()\n",
    "    cities_l = [city.lower() for city in cities]\n",
    "    _df[\"City_lower\"] = _df[\"City\"].str.lower().values\n",
    "    df_filtered = filter_valid_columnvalues(_df, \"City_lower\", valid_values=cities_l)\n",
    "    print(df_filtered.shape)\n",
    "    df_notnull = filtercols_then_dropna(df_filtered, drop_columns=[])\n",
    "    print(df_notnull.shape)\n",
    "    return df_notnull\n",
    "\n",
    "df_temperature_us_notnull = clean_temperature(df_temperature_us, cities)\n",
    "df_temperature_us_notnull.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "We chose the data model in the following table and the reasons are following:\n",
    "- We take immigration data as the fact table because this is frequently generated event data.\n",
    "- We take airports, demographics and temperature data as the dimension tables because they can be joined via airport location keys, including iata code, city name and state code.\n",
    "\n",
    "\n",
    "| table name | description | columns |\n",
    "| ------- | ---------- | ----------- |\n",
    "| immigrations | A fact table which stores all immigrations data. | \\|cicid\\|year\\|month\\|cit\\|res\\|iata\\|arrdate\\|mode\\|addr\\|depdate\\|bir\\|visa\\|coun\\|dtadfil\\|visapost\\|occup\\|entdepa\\|entdepd\\|entdepu\\|matflag\\|biryear\\|dtaddto\\|gender\\|insnum\\|airline\\|admnum\\|fltno\\|visatype\\| |\n",
    "| airports | A dimension table which stores airport information. | \\|iata_code\\|name\\|type\\|coordinates\\|city\\|state_code\\|iso_country\\|iso_region\\|gps_code\\| |\n",
    "| demographics | A dimension table which stores demographics of cities in the U.S. | \\|city\\|state_code\\|state\\|race\\|count\\|male_population\\|female_population\\|total_population\\|media_age\\|num_veterans\\|foreign_born\\|average_household_size\\| |\n",
    "| temperatures | A dimension table which stores temperature in the U.S. | \\|timestamp\\|average_temperature\\|average_temperatur_uncertainty\\|city\\|country\\|latitude\\|longitude\\| |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Join port locations in immigration data to airports data.\n",
    "2. Rename and sort columns of each table data to match the schema.\n",
    "3. Create database and each tables by executing create_tables.py.\n",
    "4. Insert data into created tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_airport_model(df_airport_notnull, iata_codes, cities, state_codes):\n",
    "    \"\"\"Make airport model dataframe to be inserted into airports table.\n",
    "    Args:\n",
    "        df_airport_notnull: DataFrame which is cleansed in prior.\n",
    "        iata_codes: Valid IATA codes specified in the SAS dictionary.\n",
    "        cities: Valid cities specified in the SAS dictionary.\n",
    "        state_codes: Valid state codes specified in the SAS dictionary.\n",
    "    Returns:\n",
    "        df_airport_model:  DataFrame to be actually inserted.\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    df_immigration_port = pd.DataFrame(\n",
    "        {\"iata_code\": iata_codes, \"city\": cities, \"state_code\": state_codes}\n",
    "    )\n",
    "    df_airport_joined = df_airport_notnull.merge(\n",
    "        df_immigration_port, left_on=\"iata_code\", right_on=\"iata_code\"\n",
    "    )\n",
    "    df_airport_model = df_airport_joined[\n",
    "        [\n",
    "            \"iata_code\",\n",
    "            \"name\",\n",
    "            \"type\",\n",
    "            \"coordinates\",\n",
    "            \"city\",\n",
    "            \"state_code\",\n",
    "            \"iso_country\",\n",
    "            \"iso_region\",\n",
    "            \"gps_code\",\n",
    "        ]\n",
    "    ]\n",
    "    return df_airport_model\n",
    "\n",
    "\n",
    "def make_demographics_model(df_demographics_notnull):\n",
    "    \"\"\"Make demographic model dataframe to be inserted into demographics table.\n",
    "    Args:\n",
    "        df_demographics_notnull: DataFrame which is cleansed in prior.\n",
    "    Returns:\n",
    "        df_demographics_model:  DataFrame to be actually inserted.\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    df_demographics_rn = df_demographics_notnull.rename(\n",
    "        columns={\n",
    "            \"City\": \"city\",\n",
    "            \"State\": \"state\",\n",
    "            \"Median Age\": \"median_age\",\n",
    "            \"Male Population\": \"male_population\",\n",
    "            \"Female Population\": \"female_population\",\n",
    "            \"Total Population\": \"total_population\",\n",
    "            \"Number of Veterans\": \"num_veterans\",\n",
    "            \"Foreign-born\": \"foreign_born\",\n",
    "            \"Average Household Size\": \"average_household_size\",\n",
    "            \"State Code\": \"state_code\",\n",
    "            \"Race\": \"race\",\n",
    "            \"Count\": \"count\",\n",
    "        }\n",
    "    )\n",
    "    df_demographics_model = df_demographics_rn[\n",
    "        [\n",
    "            \"city\",\n",
    "            \"state_code\",\n",
    "            \"state\",\n",
    "            \"race\",\n",
    "            \"count\",\n",
    "            \"male_population\",\n",
    "            \"female_population\",\n",
    "            \"total_population\",\n",
    "            \"median_age\",\n",
    "            \"num_veterans\",\n",
    "            \"foreign_born\",\n",
    "            \"average_household_size\",\n",
    "        ]\n",
    "    ]\n",
    "    return df_demographics_model\n",
    "\n",
    "\n",
    "def make_immigration_model(df_immigration_notnull):\n",
    "    \"\"\"Make immigration model dataframe to be inserted into immigrations table.\n",
    "    Args:\n",
    "        df_immigration_notnull: DataFrame which is cleansed in prior.\n",
    "    Returns:\n",
    "        df_immigration_model:  DataFrame to be actually inserted.\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    # [\"insnum\", \"entdepu\", \"occup\", \"visapost\"]\n",
    "    df_immigration_notnull_rn = df_immigration_notnull.rename(\n",
    "        columns={\n",
    "            \"cicid\": \"cicid\",\n",
    "            \"i94yr\": \"year\",\n",
    "            \"i94mon\": \"month\",\n",
    "            \"i94cit\": \"cit\",\n",
    "            \"i94res\": \"res\",\n",
    "            \"i94port\": \"iata\",\n",
    "            \"arrdate\": \"arrdate\",\n",
    "            \"i94mode\": \"mode\",\n",
    "            \"i94addr\": \"addr\",\n",
    "            \"depdate\": \"depdate\",\n",
    "            \"i94bir\": \"bir\",\n",
    "            \"i94visa\": \"visa\",\n",
    "            \"count\": \"count\",\n",
    "            \"dtadfile\": \"date_added\",\n",
    "            \"entdepa\": \"entdepa\",\n",
    "            \"entdepd\": \"entdepd\",\n",
    "            \"matflag\": \"matflag\",\n",
    "            \"biryear\": \"biryear\",\n",
    "            \"dtaddto\": \"dtaddto\",\n",
    "            \"gender\": \"gender\",\n",
    "            \"airline\": \"airline\",\n",
    "            \"admnum\": \"admnum\",\n",
    "            \"fltno\": \"fltno\",\n",
    "            \"visatype\": \"visatype\",\n",
    "        }\n",
    "    )\n",
    "    df_immigration_model = df_immigration_notnull_rn[\n",
    "        [\n",
    "            \"cicid\",\n",
    "            \"year\",\n",
    "            \"month\",\n",
    "            \"cit\",\n",
    "            \"res\",\n",
    "            \"iata\",\n",
    "            \"arrdate\",\n",
    "            \"mode\",\n",
    "            \"addr\",\n",
    "            \"depdate\",\n",
    "            \"bir\",\n",
    "            \"visa\",\n",
    "            \"count\",\n",
    "            \"date_added\",\n",
    "            \"entdepa\",\n",
    "            \"entdepd\",\n",
    "            \"matflag\",\n",
    "            \"biryear\",\n",
    "            \"dtaddto\",\n",
    "            \"gender\",\n",
    "            \"airline\",\n",
    "            \"admnum\",\n",
    "            \"fltno\",\n",
    "            \"visatype\",\n",
    "        ]\n",
    "    ]\n",
    "    return df_immigration_model\n",
    "\n",
    "\n",
    "def make_temperature_model(df_temperature_us_notnull):\n",
    "    \"\"\"Make temperature model dataframe to be inserted into temperatures table.\n",
    "    Args:\n",
    "        df_temperature_us_notnull: DataFrame which is cleansed in prior.\n",
    "    Returns:\n",
    "        df_temperature_us_model:  DataFrame to be actually inserted.\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    df_temperature_us_notnull_rn = df_temperature_us_notnull.rename(\n",
    "        columns={\n",
    "            \"dt\": \"timestamp\",\n",
    "            \"AverageTemperature\": \"average_temperature\",\n",
    "            \"AverageTemperatureUncertainty\": \"average_temperature_uncertainty\",\n",
    "            \"City\": \"city\",\n",
    "            \"Country\": \"country\",\n",
    "            \"Latitude\": \"latitude\",\n",
    "            \"Longitude\": \"longitude\",\n",
    "        }\n",
    "    )\n",
    "    df_temperature_us_model = df_temperature_us_notnull_rn[\n",
    "        [\n",
    "            \"timestamp\",\n",
    "            \"average_temperature\",\n",
    "            \"average_temperature_uncertainty\",\n",
    "            \"city\",\n",
    "            \"country\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "        ]\n",
    "    ]\n",
    "    return df_temperature_us_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airport_model = make_airport_model(df_airport_notnull, iata_codes, cities, state_codes)\n",
    "df_demographics_model = make_demographics_model(df_demographics_notnull)\n",
    "df_immigration_model = make_immigration_model(df_immigration_notnull)\n",
    "df_temperature_us_model = make_temperature_model(df_temperature_us_notnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to postgres...\n",
      "DROP EXISTING TABLES...\n",
      "CREATE TABLES...\n"
     ]
    }
   ],
   "source": [
    "!python create_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert data\n",
    "import configparser\n",
    "import psycopg2\n",
    "from sql_queries import (\n",
    "    airport_insert,\n",
    "    demographic_insert,\n",
    "    immigration_insert,\n",
    "    temperature_insert,\n",
    ")\n",
    "\n",
    "\n",
    "def insert_df_model(df_model, insert_sql, conn, cur):\n",
    "    \"\"\"Assert that the given has any rows.\n",
    "    Args:\n",
    "        df_model: DataFrame to be inserted. Its columns must match with the\n",
    "            table columns to be inserted into.\n",
    "        insert_sql: The actual INSERT SQL to be executed.\n",
    "        cur: SQL cursor object.\n",
    "        conn: DB connection object.\n",
    "    Returns:\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    for index, row in df_model.iterrows():\n",
    "        cur.execute(insert_sql, list(row.values))\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"db.cfg\")\n",
    "conn = psycopg2.connect(\n",
    "    \"host={} dbname={} user={} password={} port={}\".format(*config[\"LOCAL\"].values())\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "insert_df_model(df_airport_model, airport_insert, conn, cur)\n",
    "insert_df_model(df_demographics_model, demographic_insert, conn, cur)\n",
    "insert_df_model(df_immigration_model, immigration_insert, conn, cur)\n",
    "insert_df_model(df_temperature_us_model, temperature_insert, conn, cur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "def assert_count(cur, conn, table):\n",
    "    \"\"\" Assert that the given has any rows.\n",
    "    Args:\n",
    "        cur: SQL cursor object.\n",
    "        conn: DB connection object.\n",
    "        table: The name of table to check.\n",
    "    Returns:\n",
    "    Raises:\n",
    "        AssertionError\n",
    "    \"\"\"\n",
    "    cur.execute(f\"select count(*) from {table}\")\n",
    "    conn.commit()\n",
    "    assert cur.fetchone()[0] >= 1\n",
    "\n",
    "assert_count(cur, conn, \"airports\")\n",
    "assert_count(cur, conn, \"demographics\")\n",
    "assert_count(cur, conn, \"immigrations\")\n",
    "assert_count(cur, conn, \"temperatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def assert_key_is_notnull(cur, conn, table, colname):\n",
    "    \"\"\" Assert that the given has any rows.\n",
    "    Args:\n",
    "        cur: SQL cursor object.\n",
    "        conn: DB connection object.\n",
    "        table: The name of table to check.\n",
    "        colname: The name of column of which values must not be null.\n",
    "    Returns:\n",
    "    Raises:\n",
    "        AssertionError\n",
    "    \"\"\"\n",
    "    sql = f\"\"\"\n",
    "    select count(*) from {table}\n",
    "    where {colname} is null\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "    assert cur.fetchone()[0] == 0\n",
    "\n",
    "assert_key_is_notnull(cur, conn, \"airports\", \"iata_code\")\n",
    "assert_key_is_notnull(cur, conn, \"airports\", \"city\")\n",
    "assert_key_is_notnull(cur, conn, \"airports\", \"state_code\")\n",
    "assert_key_is_notnull(cur, conn, \"demographics\", \"city\")\n",
    "assert_key_is_notnull(cur, conn, \"demographics\", \"state_code\")\n",
    "assert_key_is_notnull(cur, conn, \"immigrations\", \"cicid\")\n",
    "assert_key_is_notnull(cur, conn, \"immigrations\", \"iata\")\n",
    "assert_key_is_notnull(cur, conn, \"temperatures\", \"timestamp\")\n",
    "assert_key_is_notnull(cur, conn, \"temperatures\", \"city\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('(Charlotte,2016,4,30,185248)',), ('(Phoenix,2016,4,60,414492)',), ('(Miami,2016,4,440,150338)',), ('(\"Fort Myers\",2016,4,20,22213)',), ('(Houston,2016,4,130,626196)',), ('(Denver,2016,4,10,174601)',), ('(McAllen,2016,4,5,46233)',), ('(\"San Diego\",2016,4,5,354034)',), ('(Vancouver,2016,4,5,39198)',), ('(Tampa,2016,4,40,92718)',)]\n"
     ]
    }
   ],
   "source": [
    "# Show analysis on immigration patterns to a city based on the overall population of the state.\n",
    "\n",
    "# config = configparser.ConfigParser()\n",
    "# config.read(\"db.cfg\")\n",
    "# conn = psycopg2.connect(\n",
    "#     \"host={} dbname={} user={} password={} port={}\".format(*config[\"LOCAL\"].values())\n",
    "# )\n",
    "# cur = conn.cursor()\n",
    "\n",
    "sql=\"\"\"select (\n",
    "  demographics.city,\n",
    "  immigrations.year,\n",
    "  immigrations.month,\n",
    "  sum(immigrations.count),\n",
    "  cast(avg(demographics.count) as integer) \n",
    ")\n",
    "from airports\n",
    "inner join immigrations on (airports.iata_code = immigrations.iata)\n",
    "inner join demographics on (lower(airports.city) = lower(demographics.city))\n",
    "group by (demographics.city, immigrations.year, immigrations.month);\n",
    "\"\"\"\n",
    "cur.execute(sql)\n",
    "print(cur.fetchmany(10))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "##### immigrations (fact table)\n",
    "\n",
    "Foreign keys are below:\n",
    "- iata: with airports table\n",
    "\n",
    "\n",
    "| Column   | Type             | Description                                                                        |\n",
    "| -------- | ---------------- | ---------------------------------------------------------------------------------- |\n",
    "| cicid    | int, primary key | ID of immigrants                                                                   |\n",
    "| year     | int              | Year of immigration                                                                |\n",
    "| month    | int              | Month of immigration                                                               |\n",
    "| cit      | int              | Contry codes from where immigrants come                                            |\n",
    "| res      | int              | Contry codes where immigrants live in                                              |\n",
    "| iata     | varchar(3)       | IATA codes of ports where immigration happen                                       |\n",
    "| arrdate  | int              | Arrival date in the U.S.                                                           |\n",
    "| mode     | int              | How immigrants come to the U.S.                                                    |\n",
    "| addr     | varchar(2)       | State code of address where immigrants will live in                                |\n",
    "| depdate  | int              | Departure date from the U.S.                                                       |\n",
    "| bir      | int              | Age of immigrants                                                                  |\n",
    "| visa     | int              | Visa code in three categories                                                      |\n",
    "| count    | int              | Count of immigration                                                               |\n",
    "| dtadfile | varchar          | Date added to I-94 Files                                                           |\n",
    "| entdepa  | varchar(1)       | Arrival flag - admitted or paroled into the U.S.                                   |\n",
    "| entdepd  | varchar(1)       | Departure flag - departed, lost I-94 or is deceased                                |\n",
    "| matflag  | varchar(1)       | Match flag - match of arrival and departure records                                |\n",
    "| biryear  | int              | 4 digit year of birth                                                              |\n",
    "| dtaddto  | varchar          | Date to which admitted to U.S.                                                     |\n",
    "| gender   | varchar(1)       | Non-immigrant sex                                                                  |\n",
    "| airline  | varchar          | Airline used to arrive in U.S.                                                     |\n",
    "| admnum   | bigint           | Admission number of immigrants                                                     |\n",
    "| fltno    | varchar          | Flight number of immigrants                                                        |\n",
    "| visatype | varchar          | Class of admission legally admitting the non-immigrant to temporarily stay in U.S. |\n",
    "\n",
    "\n",
    "##### airports\n",
    "\n",
    "Foreign keys are below:\n",
    "- city: with demographics, temperatures table\n",
    "- state_code: with demographics table\n",
    "\n",
    "| Column      | Type                    | Description               |\n",
    "| ----------- | ----------------------- | ------------------------- |\n",
    "| iata_code   | varchar(3), primary key | IATA codes of airports    |\n",
    "| name        | varchar                 | Name of airports          |\n",
    "| type        | varchar                 | Type of airports          |\n",
    "| coordinates | varchar                 | Coordicates of airports   |\n",
    "| city        | varchar                 | City where airports exist |\n",
    "| state_code  | varchar                 | State code of airports    |\n",
    "| iso_country | varchar                 | Country code of airports  |\n",
    "| iso_region  | varchar                 | Region code of airports   |\n",
    "| gps_code    | varchar                 | GPS code of airports      |\n",
    "\n",
    "\n",
    "##### demographics\n",
    "\n",
    "| Column            | Type       | Description                              |\n",
    "| ----------------- | ---------- | ---------------------------------------- |\n",
    "| city              | varchar    | City name                                |\n",
    "| state_code        | varchar(2) | State code                               |\n",
    "| state             | varchar    | State name                               |\n",
    "| race              | varchar    | Race of residents with statistics        |\n",
    "| count             | int        | Count of residents of specified race     |\n",
    "| male_population   | int        | Total count of male residents            |\n",
    "| female_population | int        | Total count of female residents          |\n",
    "| total_population  | int        | Total count of residents                 |\n",
    "| median_age        | int        | Median of ages of residents              |\n",
    "| num_veterans      | int        | Number of veterans in the city           |\n",
    "| foreign_born      | int        | Number of people who are born in foreign |\n",
    "\n",
    "##### temperatures\n",
    "\n",
    "| Column                          | Type    | Description                                    |\n",
    "| ------------------------------- | ------- | ---------------------------------------------- |\n",
    "| timestamp                       | date    | Date timestamp of the temperature is measured  |\n",
    "| average_temperature             | float   | average land temperature in celsius            |\n",
    "| average_temperature_uncertainty | float   | The 95% confidence interval around the average |\n",
    "| city                            | varchar | City name                                      |\n",
    "| country                         | varchar | Country name                                   |\n",
    "| latitude                        | varchar | Latitude value                                 |\n",
    "| longitude                       | varchar | Longitude value                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "  - We use pandas and PostgresSQL in local development. If large scale analysis is needed, these can be naturally extended to Spark and Redshift for scaling.\n",
    "\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "  - We should update the data on a monthly basis since the dataset describes immigration information that is aggregated monthly.\n",
    "\n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    "  * The data was increased by 100x.\n",
    "    - We should use Spark cluster with EMR for example to scale out ETL process. If SQL querying is slow, use columnar database like Redshift.\n",
    "  * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "    - We sholud use data workflow system like Airflow to schedule our ETL pipeline execution.\n",
    "  * The database needed to be accessed by 100+ people.\n",
    "    - We could scale out Redshift cluster to handle a large number of user requests. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
